{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c84f5b5-0a59-49a4-acde-80e233b8b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GPU_id = 7\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9fe0e5-476f-4094-95d6-0aa5514b12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cuml\n",
    "import cudf\n",
    "import cupy\n",
    "\n",
    "import logging\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8255711e-8918-44ec-aead-2454bf7de94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openproblems_bmmc_cite_phase2_mod2',\n",
       " 'openproblems_bmmc_multiome_phase2_mod2',\n",
       " 'openproblems_bmmc_cite_phase2_rna',\n",
       " 'openproblems_bmmc_multiome_phase2_rna']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/raid/data/ml/nips/datasets/predict_modality'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683e5ede-13a5-491b-bb9d-a7a9da9517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [\"GEX2ADT\", \"ADT2GEX\", \"GEX2ATAC\", \"ATAC2GEX\"]\n",
    "task2name = {\n",
    "    \"ADT2GEX\":f\"openproblems_bmmc_cite_phase2_mod2\",\n",
    "    \"GEX2ADT\":f\"openproblems_bmmc_cite_phase2_rna\",\n",
    "    \"ATAC2GEX\":f\"openproblems_bmmc_multiome_phase2_mod2\",\n",
    "    \"GEX2ATAC\":f\"openproblems_bmmc_multiome_phase2_rna\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54aef355-2b0c-4838-a5ae-848663919cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/data/ml/nips/datasets/predict_modality/openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_train_mod1.h5ad'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"GEX2ADT\"\n",
    "name = task2name[task]\n",
    "tag = \"train_mod1\"\n",
    "glob(f'{path}/{name}/*{tag}*.h5ad')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b696bb3b-238b-470d-8a9f-e6a1dbc152f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_train_mod1': '/raid/data/ml/nips/datasets/predict_modality/openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_train_mod1.h5ad',\n",
       " 'input_train_mod2': '/raid/data/ml/nips/datasets/predict_modality/openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_train_mod2.h5ad',\n",
       " 'input_test_mod1': '/raid/data/ml/nips/datasets/predict_modality/openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_test_mod1.h5ad',\n",
       " 'input_test_mod2': '/raid/data/ml/nips/datasets/predict_modality/openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_test_mod2.h5ad'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = ['train_mod1', 'train_mod2', 'test_mod1', 'test_mod2']\n",
    "par = {f'input_{tag}': glob(f'{path}/{name}/*{tag}*.h5ad')[0] for tag in tags}\n",
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c9ecf2-eb4f-4370-b786-fba8bcce316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shape(*x):\n",
    "    for i in x:\n",
    "        print(i.shape, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31387dc7-ca33-4984-89d7-cc528f53b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66175, 13953) (66175, 134) (1000, 13953) (1000, 134) \n",
      "CPU times: user 6.28 s, sys: 845 ms, total: 7.13 s\n",
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_train_mod1 = ad.read_h5ad(par['input_train_mod1'])\n",
    "input_train_mod2 = ad.read_h5ad(par['input_train_mod2'])\n",
    "input_test_mod1 = ad.read_h5ad(par['input_test_mod1'])\n",
    "input_test_mod2 = ad.read_h5ad(par['input_test_mod2'])\n",
    "\n",
    "print_shape(input_train_mod1, input_train_mod2, input_test_mod1, input_test_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6235f0-dbb7-4e14-82d3-4b27b58eab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pred_dimx = input_test_mod1.shape[0]\n",
    "pred_dimy = input_train_mod2.shape[1]\n",
    "\n",
    "feature_obs = input_train_mod1.obs\n",
    "gs_obs = input_train_mod2.obs\n",
    "\n",
    "batches = input_train_mod1.obs.batch.unique().tolist()\n",
    "batch_len = len(batches)\n",
    "\n",
    "obs = input_test_mod1.obs\n",
    "var = input_train_mod2.var\n",
    "dataset_id = input_train_mod1.uns['dataset_id']\n",
    "\n",
    "input_train = ad.concat(\n",
    "    {\"train\": input_train_mod1, \"test\": input_test_mod1},\n",
    "    axis=0,\n",
    "    join=\"outer\",\n",
    "    label=\"group\",\n",
    "    fill_value=0,\n",
    "    index_unique=\"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16e786-35a1-41ce-a8d9-d5cce6115dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Determine parameters by the modalities')\n",
    "mod1_type = input_train_mod1.var.feature_types[0]\n",
    "mod1_type = mod1_type.upper()\n",
    "mod2_type = input_train_mod2.var.feature_types[0]\n",
    "mod2_type = mod2_type.upper()\n",
    "mod1_type, mod2_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bbd7e-78e6-4eed-abd6-95d3b01c4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp_dict = {\n",
    "        (\"GEX\", \"ADT\"): (300, 70, 10, 0.2),\n",
    "        (\"ADT\", \"GEX\"): (None, 50, 10, 0.2),\n",
    "        (\"GEX\", \"ATAC\"): (1000, 50, 10, 0.1),\n",
    "        (\"ATAC\", \"GEX\"): (100, 70, 10, 0.1)\n",
    "        }\n",
    "print(f\"{mod1_type}, {mod2_type}\")\n",
    "n_mod1, n_mod2, scale, alpha = n_comp_dict[(mod1_type, mod2_type)]\n",
    "print(f\"{n_mod1}, {n_mod2}, {scale}, {alpha}\")\n",
    "\n",
    "# Do PCA on the input data\n",
    "print('Models using the Truncated SVD to reduce the dimension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae735dc-354d-46e0-8e86-583bb5eec811",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X = cupy.asarray(input_train.X.toarray(), order='F')\n",
    "y = cupy.asarray(input_train_mod2.X.toarray(), order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32529e41-e938-4131-bcd0-6e7c161d64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_mask(ds, val):\n",
    "    r = ds == val\n",
    "    return r.values\n",
    "\n",
    "if n_mod1 is not None and n_mod1 < input_train.shape[1]:\n",
    "    embedder_mod1 = cuml.decomposition.TruncatedSVD(n_components=n_mod1)\n",
    "    mod1_pca = embedder_mod1.fit_transform(X).astype(np.float32)\n",
    "    train_matrix = mod1_pca[get_mask(input_train.obs['group'],'train')]\n",
    "    test_matrix = mod1_pca[get_mask(input_train.obs['group'],'test')]\n",
    "else:\n",
    "    train_matrix = input_train_mod1.to_df().values.astype(np.float32)\n",
    "    test_matrix = input_test_mod1.to_df().values.astype(np.float32)\n",
    "\n",
    "if n_mod2 is not None and n_mod2 < input_train_mod2.shape[1]:\n",
    "    embedder_mod2 = cuml.decomposition.TruncatedSVD(n_components=n_mod2)\n",
    "    train_gs = embedder_mod2.fit_transform(y).astype(np.float32)\n",
    "else:\n",
    "    train_gs = input_train_mod2.to_df().values.astype(np.float32)\n",
    "\n",
    "del input_train\n",
    "del input_train_mod1\n",
    "del input_train_mod2\n",
    "del input_test_mod1\n",
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7dadc-e182-4832-b833-e3dba8174b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('Running normalization ...')\n",
    "train_sd = np.std(train_matrix, axis=1).reshape(-1, 1)\n",
    "train_sd[train_sd == 0] = 1\n",
    "train_norm = (train_matrix - np.mean(train_matrix, axis=1).reshape(-1, 1)) / train_sd\n",
    "train_norm = train_norm.astype(np.float32)\n",
    "del train_matrix\n",
    "\n",
    "test_sd = np.std(test_matrix, axis=1).reshape(-1, 1)\n",
    "test_sd[test_sd == 0] = 1\n",
    "test_norm = (test_matrix - np.mean(test_matrix, axis=1).reshape(-1, 1)) / test_sd\n",
    "test_norm = test_norm.astype(np.float32)\n",
    "del test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940c388-2edc-4dfa-80f9-38120082e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuml.metrics.PAIRWISE_KERNEL_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330cd287-79a3-4d21-9b8d-d8cf24ff4bc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from cupy import linalg\n",
    "import cupy as cp\n",
    "from cupyx import lapack, geterr, seterr\n",
    "from cuml.common.array_descriptor import CumlArrayDescriptor\n",
    "from cuml.common.base import Base\n",
    "from cuml.common.mixins import RegressorMixin\n",
    "from cuml.common.doc_utils import generate_docstring\n",
    "from cuml.common import input_to_cuml_array\n",
    "\n",
    "from cuml.metrics import pairwise_kernels\n",
    "\n",
    "\n",
    "# cholesky solve with fallback to least squares for singular problems\n",
    "def _safe_solve(K, y):\n",
    "    try:\n",
    "        # we need to set the error mode of cupy to raise\n",
    "        # otherwise we silently get an array of NaNs\n",
    "        err_mode = geterr()[\"linalg\"]\n",
    "        seterr(linalg=\"raise\")\n",
    "        dual_coef = lapack.posv(K, y)\n",
    "        seterr(linalg=err_mode)\n",
    "    except np.linalg.LinAlgError:\n",
    "        warnings.warn(\n",
    "            \"Singular matrix in solving dual problem. Using \"\n",
    "            \"least-squares solution instead.\"\n",
    "        )\n",
    "        dual_coef = linalg.lstsq(K, y, rcond=None)[0]\n",
    "    return dual_coef\n",
    "\n",
    "\n",
    "def _solve_cholesky_kernel(K, y, alpha, sample_weight=None):\n",
    "    # dual_coef = inv(X X^t + alpha*Id) y\n",
    "    n_samples = K.shape[0]\n",
    "    n_targets = y.shape[1]\n",
    "\n",
    "    K = cp.array(K, dtype=np.float64)\n",
    "\n",
    "    alpha = cp.atleast_1d(alpha)\n",
    "    one_alpha = alpha.size == 1\n",
    "    has_sw = sample_weight is not None\n",
    "\n",
    "    if has_sw:\n",
    "        # Unlike other solvers, we need to support sample_weight directly\n",
    "        # because K might be a pre-computed kernel.\n",
    "        sw = cp.sqrt(cp.atleast_1d(sample_weight))\n",
    "        y = y * sw[:, cp.newaxis]\n",
    "        K *= cp.outer(sw, sw)\n",
    "\n",
    "    if one_alpha:\n",
    "        # Only one penalty, we can solve multi-target problems in one time.\n",
    "        K.flat[:: n_samples + 1] += alpha[0]\n",
    "\n",
    "        dual_coef = _safe_solve(K, y)\n",
    "\n",
    "        if has_sw:\n",
    "            dual_coef *= sw[:, cp.newaxis]\n",
    "\n",
    "        return dual_coef\n",
    "    else:\n",
    "        # One penalty per target. We need to solve each target separately.\n",
    "        dual_coefs = cp.empty([n_targets, n_samples], K.dtype)\n",
    "\n",
    "        for dual_coef, target, current_alpha in zip(dual_coefs, y.T, alpha):\n",
    "            K.flat[:: n_samples + 1] += current_alpha\n",
    "\n",
    "            dual_coef[:] = _safe_solve(K, target).ravel()\n",
    "\n",
    "            K.flat[:: n_samples + 1] -= current_alpha\n",
    "\n",
    "        if has_sw:\n",
    "            dual_coefs *= sw[cp.newaxis, :]\n",
    "\n",
    "        return dual_coefs.T\n",
    "class KernelRidgeMultiOutput(cuml.kernel_ridge.KernelRidge):\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None,\n",
    "            convert_dtype=True) -> \"KernelRidge\":\n",
    "\n",
    "        ravel = False\n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "            ravel = True\n",
    "\n",
    "        X_m, n_rows, self.n_cols, self.dtype = input_to_cuml_array(\n",
    "            X, check_dtype=[np.float32, np.float64]\n",
    "        )\n",
    "\n",
    "        y_m, _, _, _ = input_to_cuml_array(\n",
    "            y,\n",
    "            check_dtype=self.dtype,\n",
    "            convert_to_dtype=(self.dtype if convert_dtype else None),\n",
    "            check_rows=n_rows,\n",
    "        )\n",
    "\n",
    "        if self.n_cols < 1:\n",
    "            msg = \"X matrix must have at least a column\"\n",
    "            raise TypeError(msg)\n",
    "\n",
    "        K = self._get_kernel(X_m)\n",
    "        \n",
    "        self.dual_coef_ = []\n",
    "        y_m = y_m.to_output('cupy')\n",
    "        for i in range(y_m.shape[1]):\n",
    "            coef = _solve_cholesky_kernel(\n",
    "                K, y_m[:,i], self.alpha, sample_weight\n",
    "            )\n",
    "            if ravel:\n",
    "                coef = coef.ravel()\n",
    "            self.dual_coef_.append(coef)\n",
    "        self.X_fit_ = X_m\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the kernel ridge model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Samples. If kernel == \"precomputed\" this is instead a\n",
    "            precomputed kernel matrix, shape = [n_samples,\n",
    "            n_samples_fitted], where n_samples_fitted is the number of\n",
    "            samples used in the fitting for this estimator.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        C : array of shape (n_samples,) or (n_samples, n_targets)\n",
    "            Returns predicted values.\n",
    "        \"\"\"\n",
    "        X_m, _, _, _ = input_to_cuml_array(\n",
    "            X, check_dtype=[np.float32, np.float64])\n",
    "\n",
    "        K = self._get_kernel(X_m, self.X_fit_)\n",
    "        K = cp.asarray(K)\n",
    "        yps = []\n",
    "        for coef in self.dual_coef_:\n",
    "            yps.append(cp.dot(K, cp.asarray(coef)))\n",
    "        return cp.array(yps).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5b9d9-0217-4a3b-8087-8063d040b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print('Running KRR model ...')\n",
    "y_pred = cupy.zeros((pred_dimx, pred_dimy), dtype=np.float32)\n",
    "cupy.random.seed(1000)\n",
    "emb = embedder_mod2.components_.to_output('cupy')\n",
    "for _ in tqdm(range(5)):\n",
    "    np.random.shuffle(batches)\n",
    "    for batch in [batches[:batch_len//2], batches[batch_len//2:]]:\n",
    "        # for passing the test\n",
    "        if not batch:\n",
    "            batch = [batches[0]]\n",
    "\n",
    "        logging.info(batch)\n",
    "        \n",
    "        print('Fitting KRR ... ')\n",
    "        x = train_norm[feature_obs.batch.isin(batch).values]\n",
    "        y = train_gs[gs_obs.batch.isin(batch).values]\n",
    "        krr = cuml.kernel_ridge.KernelRidge(alpha=alpha, kernel='rbf')\n",
    "        krr.fit(x, y)\n",
    "        gc.collect()\n",
    "        yp = krr.predict(test_norm)\n",
    "        yp = yp @ emb\n",
    "        y_pred += yp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b4e03-1a45-4476-bb23-9b0665f32974",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.get()\n",
    "np.clip(y_pred, a_min=0, a_max=None, out=y_pred)\n",
    "if mod2_type == \"ATAC\":\n",
    "    np.clip(y_pred, a_min=0, a_max=1, out=y_pred)\n",
    "\n",
    "y_pred /= 10\n",
    "\n",
    "# Store as sparse matrix to be efficient. Note that this might require\n",
    "# different classifiers/embedders before-hand. Not every class is able\n",
    "# to support such data structures.\n",
    "y_pred = csc_matrix(y_pred)\n",
    "\n",
    "logging.info(\"Generate anndata object ...\")\n",
    "adata = ad.AnnData(\n",
    "    X=y_pred,\n",
    "    obs=obs,\n",
    "    var=var,\n",
    "    uns={\n",
    "        'dataset_id': dataset_id,\n",
    "        'method_id': 'gpu',\n",
    "    },\n",
    ")\n",
    "\n",
    "logging.info('Storing annotated data...')\n",
    "adata.write_h5ad('gpu.h5ad', compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8f62bbc-9e2b-4c56-8498-2d2fd6b678ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "yx = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee6a076e-8088-425a-afae-9ac0e4bb41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16873707, 0.23536715, 0.61948097, ..., 0.39800423, 0.42028886,\n",
       "        0.52114236],\n",
       "       [0.04233083, 0.28994787, 0.65432906, ..., 0.21106711, 0.36479193,\n",
       "        0.24584863],\n",
       "       [0.02861868, 0.2421951 , 0.6622361 , ..., 0.1731327 , 0.39247906,\n",
       "        0.16301864],\n",
       "       ...,\n",
       "       [0.0712819 , 0.22787991, 0.53754294, ..., 0.28534326, 0.36496112,\n",
       "        0.23056659],\n",
       "       [0.0727509 , 0.18692048, 0.5490494 , ..., 0.15434405, 0.3627604 ,\n",
       "        0.2049741 ],\n",
       "       [0.0495175 , 0.3464053 , 0.6344657 , ..., 0.22001934, 0.38574556,\n",
       "        0.31911534]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110853b-683b-482f-88cd-de0542abf741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
